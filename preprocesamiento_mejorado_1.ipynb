{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocesamiento Mejorado - Pump it Up Dataset\n",
        "\n",
        "Este notebook implementa un preprocesamiento mejorado que incluye:\n",
        "1. **Procesamiento de variables temporales** (extracción de características de fechas)\n",
        "2. **KNN Imputer** para imputación de valores faltantes\n",
        "3. **Eliminación de variables muy correlacionadas** (umbral > 0.95) con explicación detallada de decisiones\n",
        "\n",
        "Dataset: Pump it Up: Data Mining the Water Table\n",
        "Fuente: https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports necesarios\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar datos de entrenamiento y prueba\n",
        "X_train = pd.read_csv(\"X_train.csv\")\n",
        "y_train = pd.read_csv(\"y_train.csv\")\n",
        "X_test = pd.read_csv(\"X_test.csv\")\n",
        "y_test = pd.read_csv(\"y_test.csv\")\n",
        "\n",
        "print(f\"Forma de X_train: {X_train.shape}\")\n",
        "print(f\"Forma de y_train: {y_train.shape}\")\n",
        "print(f\"Forma de X_test: {X_test.shape}\")\n",
        "print(f\"Forma de y_test: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Exploración inicial de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Información general del dataset\n",
        "X_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Valores faltantes\n",
        "print(\"Valores faltantes por columna:\")\n",
        "missing_values = X_train.isna().sum().sort_values(ascending=False)\n",
        "print(missing_values[missing_values > 0])\n",
        "\n",
        "print(\"\\nPorcentaje de valores faltantes:\")\n",
        "missing_pct = (X_train.isna().mean() * 100).sort_values(ascending=False)\n",
        "print(missing_pct[missing_pct > 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Preprocesamiento mejorado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Eliminar variables que no aportan información"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Eliminar variables que no se usan (aplicar a train y test)\n",
        "variables_a_eliminar_inicial = [\"scheme_name\",\"scheme_management\", \"id\",\"date_recorded\",\"recorded_by\",\"num_private \"]\n",
        "#NO APORTAN INFORMACIÓN ÚTIL \n",
        "\n",
        "X_train = X_train.drop(columns=variables_a_eliminar_inicial, errors=\"ignore\")\n",
        "X_test = X_test.drop(columns=variables_a_eliminar_inicial, errors=\"ignore\")\n",
        "\n",
        "print(f\"Variables después de eliminar: X_train={X_train.shape[1]}, X_test={X_test.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Separar variables categóricas y numéricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separar variables categóricas y numéricas\n",
        "columnas_categoricas = X_train.select_dtypes(include=\"object\").columns.tolist()\n",
        "columnas_numericas = X_train.select_dtypes(exclude=\"object\").columns.tolist()\n",
        "\n",
        "print(f\"Variables categóricas: {len(columnas_categoricas)}\")\n",
        "print(f\"Variables numéricas: {len(columnas_numericas)}\")\n",
        "print(f\"\\nCategóricas: {columnas_categoricas}\")\n",
        "print(f\"\\nNuméricas: {columnas_numericas}\")\n",
        "\n",
        "# Identificar variables temporales\n",
        "variables_temporales = []\n",
        "if \"date_recorded\" in X_train.columns:\n",
        "    variables_temporales.append(\"date_recorded\")\n",
        "if \"construction_year\" in X_train.columns:\n",
        "    variables_temporales.append(\"construction_year\")\n",
        "\n",
        "if variables_temporales:\n",
        "    print(f\"\\nVariables temporales identificadas: {variables_temporales}\")\n",
        "else:\n",
        "    print(\"\\nNo se encontraron variables temporales\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4 Convertir ceros problemáticos a NaN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identificar columnas donde el 0 puede ser un valor faltante\n",
        "zero_as_nan_cols = [\n",
        "    \"amount_tsh\",\n",
        "    \"gps_height\",\n",
        "    \"longitude\",\n",
        "    \"population\",\n",
        "    \"num_private\",\n",
        "    \"construction_year\"\n",
        "]\n",
        "\n",
        "# Convertir ceros a NaN en estas columnas (aplicar a train y test)\n",
        "X_train_num = X_train[columnas_numericas].copy()\n",
        "X_test_num = X_test[columnas_numericas].copy()\n",
        "\n",
        "X_train_num[zero_as_nan_cols] = X_train_num[zero_as_nan_cols].replace(0, np.nan)\n",
        "X_test_num[zero_as_nan_cols] = X_test_num[zero_as_nan_cols].replace(0, np.nan)\n",
        "\n",
        "print(f\"Valores NaN en X_train después de convertir ceros:\")\n",
        "print(X_train_num.isna().sum()[X_train_num.isna().sum() > 0])\n",
        "print(f\"\\nValores NaN en X_test después de convertir ceros:\")\n",
        "print(X_test_num.isna().sum()[X_test_num.isna().sum() > 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.5 Imputación con KNN Imputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preparar datasets para KNN Imputer\n",
        "# Convertir todas las variables categóricas a numéricas usando pd.factorize()\n",
        "# IMPORTANTE: Usar los mismos códigos de factorize para train y test\n",
        "X_train_for_knn = X_train.copy()\n",
        "X_test_for_knn = X_test.copy()\n",
        "\n",
        "print(\"Convirtiendo atributos categóricos a numéricos con pd.factorize()...\")\n",
        "# Guardar los mapeos de factorize para aplicar los mismos códigos a test\n",
        "factorize_mappings = {}\n",
        "\n",
        "for column in columnas_categoricas:\n",
        "    if column in X_train_for_knn.columns:\n",
        "        # Aplicar factorize en train\n",
        "        codes, uniques = pd.factorize(X_train_for_knn[column])\n",
        "        X_train_for_knn[column] = codes\n",
        "        X_train_for_knn[column].replace(-1, np.nan, inplace=True)\n",
        "        \n",
        "        # Guardar el mapeo para aplicar a test\n",
        "        factorize_mappings[column] = uniques\n",
        "        \n",
        "        # Aplicar el mismo mapeo a test\n",
        "        if column in X_test_for_knn.columns:\n",
        "            # Mapear valores de test usando los códigos de train\n",
        "            X_test_for_knn[column] = X_test_for_knn[column].map(dict(zip(uniques, range(len(uniques)))))\n",
        "            # Valores no vistos en train se convierten en NaN\n",
        "            X_test_for_knn[column] = X_test_for_knn[column].where(X_test_for_knn[column].notna(), np.nan)\n",
        "\n",
        "print(f\"✓ Variables categóricas convertidas a numéricas\")\n",
        "print(f\"Forma X_train: {X_train_for_knn.shape}, Valores faltantes: {X_train_for_knn.isna().sum().sum()}\")\n",
        "print(f\"Forma X_test: {X_test_for_knn.shape}, Valores faltantes: {X_test_for_knn.isna().sum().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aplicar KNN Imputer: fit en train, transform en train y test\n",
        "print(\"Aplicando KNN Imputer (esto puede tardar unos minutos)...\")\n",
        "knn_imputer = KNNImputer(n_neighbors=5)  # Puedes probar con otro valor de vecinos\n",
        "\n",
        "# Ajustar el imputador con train y transformar train y test\n",
        "X_train_imputed = pd.DataFrame(\n",
        "    knn_imputer.fit_transform(X_train_for_knn),\n",
        "    columns=X_train_for_knn.columns,\n",
        "    index=X_train_for_knn.index\n",
        ")\n",
        "\n",
        "X_test_imputed = pd.DataFrame(\n",
        "    knn_imputer.transform(X_test_for_knn),\n",
        "    columns=X_test_for_knn.columns,\n",
        "    index=X_test_for_knn.index\n",
        ")\n",
        "\n",
        "print(\"✓ KNN Imputer completado\")\n",
        "print(f\"X_train - Valores faltantes después de imputación: {X_train_imputed.isna().sum().sum()}\")\n",
        "print(f\"X_test - Valores faltantes después de imputación: {X_test_imputed.isna().sum().sum()}\")\n",
        "print(f\"\\nVerificación X_train:\")\n",
        "missing_after_train = X_train_imputed.isnull().sum()\n",
        "print(missing_after_train[missing_after_train > 0] if missing_after_train.sum() > 0 else \"✓ No hay valores faltantes\")\n",
        "print(f\"\\nVerificación X_test:\")\n",
        "missing_after_test = X_test_imputed.isnull().sum()\n",
        "print(missing_after_test[missing_after_test > 0] if missing_after_test.sum() > 0 else \"✓ No hay valores faltantes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Los datasets ya están completamente imputados y todas las variables son numéricas\n",
        "# Separar en numéricas originales y categóricas (ahora convertidas a numéricas)\n",
        "X_train_num_imp = X_train_imputed[columnas_numericas].copy()\n",
        "X_test_num_imp = X_test_imputed[columnas_numericas].copy()\n",
        "\n",
        "# Las categóricas ahora están como números (después de factorize y KNN)\n",
        "# Podemos mantenerlas así o volver a convertirlas a categóricas si es necesario\n",
        "X_train_cat_imp = X_train_imputed[columnas_categoricas].copy()\n",
        "X_test_cat_imp = X_test_imputed[columnas_categoricas].copy()\n",
        "\n",
        "print(\"✓ Datasets imputados listos\")\n",
        "print(f\"X_train - Variables numéricas: {X_train_num_imp.shape[1]}, categóricas: {X_train_cat_imp.shape[1]}\")\n",
        "print(f\"X_test - Variables numéricas: {X_test_num_imp.shape[1]}, categóricas: {X_test_cat_imp.shape[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Los datasets ya están completamente imputados y todas las variables son numéricas\n",
        "X_train_imputado = X_train_imputed.copy()\n",
        "X_test_imputado = X_test_imputed.copy()\n",
        "\n",
        "print(f\"X_train completo imputado: {X_train_imputado.shape}\")\n",
        "print(f\"X_test completo imputado: {X_test_imputado.shape}\")\n",
        "print(f\"X_train - Valores faltantes: {X_train_imputado.isna().sum().sum()}\")\n",
        "print(f\"X_test - Valores faltantes: {X_test_imputado.isna().sum().sum()}\")\n",
        "print(f\"\\n✓ Todas las variables están ahora como numéricas (categóricas convertidas con factorize)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Los datasets ya están completos y listos para usar\n",
        "# Todas las variables (numéricas y categóricas) están ahora como numéricas\n",
        "print(f\"\\n✓ Preprocesamiento con KNN Imputer completado\")\n",
        "print(f\"X_train final: {X_train_imputado.shape}\")\n",
        "print(f\"X_test final: {X_test_imputado.shape}\")\n",
        "print(f\"Todas las variables son numéricas (categóricas convertidas con pd.factorize())\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Eliminación de variables muy correlacionadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear una copia para calcular correlaciones\n",
        "# Las variables categóricas ya están como numéricas (después de factorize y KNN)\n",
        "# así que podemos calcular correlaciones directamente\n",
        "X_train_for_corr = X_train_imputado.copy()\n",
        "\n",
        "print(\"✓ Dataset listo para análisis de correlación\")\n",
        "print(\"  (Las categóricas ya están como numéricas después de factorize)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calcular matriz de correlación\n",
        "correlation_matrix = X_train_for_corr.corr().abs()\n",
        "\n",
        "# Crear máscara para la parte superior de la matriz (para evitar duplicados)\n",
        "upper_triangle = np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool)\n",
        "\n",
        "# Encontrar pares de variables con correlación muy alta (umbral: 0.95)\n",
        "high_corr_pairs = []\n",
        "for i in range(len(correlation_matrix.columns)):\n",
        "    for j in range(i+1, len(correlation_matrix.columns)):\n",
        "        if upper_triangle[i, j] and correlation_matrix.iloc[i, j] > 0.8:\n",
        "            high_corr_pairs.append((\n",
        "                correlation_matrix.columns[i],\n",
        "                correlation_matrix.columns[j],\n",
        "                correlation_matrix.iloc[i, j]\n",
        "            ))\n",
        "\n",
        "print(f\"Variables muy correlacionadas (correlación > 0.95): {len(high_corr_pairs)} pares\")\n",
        "if high_corr_pairs:\n",
        "    print(\"\\nPrimeros 10 pares encontrados:\")\n",
        "    for var1, var2, corr in high_corr_pairs[:10]:\n",
        "        print(f\"  {var1} <-> {var2}: {corr:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Eliminar variables específicas que no aportan información útil (aplicar a train y test)\n",
        "variables_a_eliminar = [\n",
        "    \"id\",\n",
        "    \"water_quality\",\n",
        "    \"payment\",\n",
        "    \"source\",\n",
        "    \"source_class\",\n",
        "    \"extraction_type_group\",\n",
        "    \"quantity_group\",\n",
        "    \"waterpoint_type_group\",\n",
        "    \"management\",\n",
        "    \"region_code\",\n",
        "    \"district_code\"\n",
        "]\n",
        "\n",
        "# Verificar qué variables existen en el dataset antes de eliminar\n",
        "variables_existentes = [var for var in variables_a_eliminar if var in X_train_imputado.columns]\n",
        "variables_no_existentes = [var for var in variables_a_eliminar if var not in X_train_imputado.columns]\n",
        "\n",
        "print(\"Eliminando variables específicas...\")\n",
        "print(f\"\\nVariables a eliminar que existen en el dataset ({len(variables_existentes)}):\")\n",
        "for var in variables_existentes:\n",
        "    print(f\"  - {var}\")\n",
        "\n",
        "if variables_no_existentes:\n",
        "    print(f\"\\nVariables a eliminar que NO existen en el dataset ({len(variables_no_existentes)}):\")\n",
        "    for var in variables_no_existentes:\n",
        "        print(f\"  - {var}\")\n",
        "\n",
        "# Eliminar las variables de ambos datasets\n",
        "X_train_imputado = X_train_imputado.drop(columns=variables_existentes, errors=\"ignore\")\n",
        "X_test_imputado = X_test_imputado.drop(columns=variables_existentes, errors=\"ignore\")\n",
        "\n",
        "# Actualizar las listas de columnas\n",
        "columnas_categoricas = [c for c in columnas_categoricas if c not in variables_existentes]\n",
        "columnas_numericas = [c for c in columnas_numericas if c not in variables_existentes]\n",
        "\n",
        "print(f\"\\n✓ Variables eliminadas: {len(variables_existentes)}\")\n",
        "print(f\"✓ Variables restantes en X_train_imputado: {X_train_imputado.shape[1]}\")\n",
        "print(f\"✓ Variables restantes en X_test_imputado: {X_test_imputado.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Preparación final para modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Después de eliminar variables correlacionadas, el dataset ya está listo\n",
        "# Todas las variables (numéricas y categóricas) están como numéricas\n",
        "print(f\"Variables numéricas originales: {len([c for c in columnas_numericas if c in X_train_imputado.columns])}\")\n",
        "print(f\"Variables categóricas (convertidas a numéricas): {len([c for c in columnas_categoricas if c in X_train_imputado.columns])}\")\n",
        "print(f\"Total de variables: {X_train_imputado.shape[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Las variables categóricas ya están como numéricas (después de factorize y KNN)\n",
        "# No necesitamos codificarlas de nuevo, ya están listas para los modelos\n",
        "print(\"✓ Todas las variables están listas para los modelos\")\n",
        "print(\"  (Las categóricas ya están como numéricas después de factorize y KNN)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Los datasets ya están completos y listos para los modelos\n",
        "X_train_prep = X_train_imputado.copy()\n",
        "X_test_prep = X_test_imputado.copy()\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RESUMEN DEL PREPROCESAMIENTO\")\n",
        "print(\"=\"*50)\n",
        "print(f\"X_train - Forma final: {X_train_prep.shape}\")\n",
        "print(f\"X_test - Forma final: {X_test_prep.shape}\")\n",
        "print(f\"X_train - Valores faltantes: {X_train_prep.isna().sum().sum()}\")\n",
        "print(f\"X_test - Valores faltantes: {X_test_prep.isna().sum().sum()}\")\n",
        "print(f\"Variables numéricas originales: {len([c for c in columnas_numericas if c in X_train_prep.columns])}\")\n",
        "print(f\"Variables categóricas (convertidas a numéricas): {len([c for c in columnas_categoricas if c in X_train_prep.columns])}\")\n",
        "print(f\"\\n✓ Datasets listos para entrenar modelos\")\n",
        "print(f\"  (Todas las variables son numéricas)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Verificación final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verificar que no hay valores faltantes\n",
        "assert X_train_prep.isna().sum().sum() == 0, \"¡X_train aún tiene valores faltantes!\"\n",
        "assert X_test_prep.isna().sum().sum() == 0, \"¡X_test aún tiene valores faltantes!\"\n",
        "print(\"✓ Verificación: No hay valores faltantes en train ni test\")\n",
        "\n",
        "# Verificar que las formas coinciden\n",
        "assert X_train_prep.shape[0] == X_train.shape[0], \"¡El número de filas de X_train no coincide!\"\n",
        "assert X_test_prep.shape[0] == X_test.shape[0], \"¡El número de filas de X_test no coincide!\"\n",
        "assert X_train_prep.shape[1] == X_test_prep.shape[1], \"¡El número de columnas no coincide entre train y test!\"\n",
        "print(f\"✓ Verificación: Número de filas correcto (X_train: {X_train_prep.shape[0]}, X_test: {X_test_prep.shape[0]})\")\n",
        "print(f\"✓ Verificación: Número de columnas coincide ({X_train_prep.shape[1]})\")\n",
        "\n",
        "print(\"\\n✓ Preprocesamiento completado exitosamente\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Guardar datos preprocesados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Guardar los datos preprocesados en archivos CSV para usar en los modelos\n",
        "X_train_prep = X_train_imputado.copy()\n",
        "X_test_prep = X_test_imputado.copy()\n",
        "\n",
        "X_train_prep.to_csv('X_train_prep.csv', index=False)\n",
        "X_test_prep.to_csv('X_test_prep.csv', index=False)\n",
        "\n",
        "print(\"✓ Datos preprocesados guardados:\")\n",
        "print(f\"  - X_train_prep.csv: {X_train_prep.shape}\")\n",
        "print(f\"  - X_test_prep.csv: {X_test_prep.shape}\")\n",
        "print(f\"\\n✓ Datasets listos para entrenar modelos\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
