{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33d6e60c",
   "metadata": {},
   "source": [
    "# **KNN y Bagging**\n",
    "## *Práctica para la evaluación de la asignatura*\n",
    "\n",
    "> **Parte de:** Carmen Quiles Ramírez  \n",
    "> **Correo:** `carmenquilesr@correo.ugr.es`  \n",
    "> **Fecha:** *4/1/2026*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98e2049",
   "metadata": {},
   "source": [
    "Para garantizar la reproducibilidad y el rigor metodológico, iniciamos el entorno importando las librerías de scikit-learn necesarias para la construcción de Pipelines. Es fundamental destacar que trabajamos exclusivamente sobre el conjunto de entrenamiento (X_train), manteniendo el conjunto de test aislado para evitar el data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac5b336a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del Training: (47520, 40)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>num_private</th>\n",
       "      <th>basin</th>\n",
       "      <th>subvillage</th>\n",
       "      <th>region</th>\n",
       "      <th>region_code</th>\n",
       "      <th>district_code</th>\n",
       "      <th>lga</th>\n",
       "      <th>ward</th>\n",
       "      <th>population</th>\n",
       "      <th>public_meeting</th>\n",
       "      <th>recorded_by</th>\n",
       "      <th>scheme_management</th>\n",
       "      <th>scheme_name</th>\n",
       "      <th>permit</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>extraction_type</th>\n",
       "      <th>extraction_type_group</th>\n",
       "      <th>extraction_type_class</th>\n",
       "      <th>management</th>\n",
       "      <th>management_group</th>\n",
       "      <th>payment</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>454.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>27/02/2013</td>\n",
       "      <td>Dmdd</td>\n",
       "      <td>2092.0</td>\n",
       "      <td>DMDD</td>\n",
       "      <td>35.426020</td>\n",
       "      <td>-4.227446</td>\n",
       "      <td>Narmo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Internal</td>\n",
       "      <td>Bashnet Kati</td>\n",
       "      <td>Manyara</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Babati</td>\n",
       "      <td>Bashinet</td>\n",
       "      <td>160.0</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>Water Board</td>\n",
       "      <td>K</td>\n",
       "      <td>True</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>water board</td>\n",
       "      <td>user-group</td>\n",
       "      <td>pay per bucket</td>\n",
       "      <td>per bucket</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>510.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17/03/2011</td>\n",
       "      <td>Cmsr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Gove</td>\n",
       "      <td>35.510074</td>\n",
       "      <td>-5.724555</td>\n",
       "      <td>Lukali</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Internal</td>\n",
       "      <td>Lukali</td>\n",
       "      <td>Dodoma</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Bahi</td>\n",
       "      <td>Lamaiti</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>VWC</td>\n",
       "      <td>K</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>india mark ii</td>\n",
       "      <td>india mark ii</td>\n",
       "      <td>handpump</td>\n",
       "      <td>vwc</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>hand pump</td>\n",
       "      <td>hand pump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14146.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10/07/2011</td>\n",
       "      <td>Kkkt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>KKKT</td>\n",
       "      <td>32.499866</td>\n",
       "      <td>-9.081222</td>\n",
       "      <td>Mahakama</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lake Rukwa</td>\n",
       "      <td>Chawalikozi</td>\n",
       "      <td>Mbeya</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Mbozi</td>\n",
       "      <td>Ndalambo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>VWC</td>\n",
       "      <td>K</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>vwc</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47410.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12/04/2011</td>\n",
       "      <td>Government Of Tanzania</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DWE</td>\n",
       "      <td>34.060484</td>\n",
       "      <td>-8.830208</td>\n",
       "      <td>Shule Ya Msingi Chosi A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rufiji</td>\n",
       "      <td>Shuleni</td>\n",
       "      <td>Mbeya</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Mbarali</td>\n",
       "      <td>Chimala</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>VWC</td>\n",
       "      <td>K</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>vwc</td>\n",
       "      <td>user-group</td>\n",
       "      <td>pay monthly</td>\n",
       "      <td>monthly</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>river</td>\n",
       "      <td>river/lake</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1288.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>05/04/2011</td>\n",
       "      <td>Ki</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>Ki</td>\n",
       "      <td>37.032690</td>\n",
       "      <td>-6.040787</td>\n",
       "      <td>Kwa Mjowe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Wami / Ruvu</td>\n",
       "      <td>Ngholong</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Kilosa</td>\n",
       "      <td>Chakwale</td>\n",
       "      <td>120.0</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>VWC</td>\n",
       "      <td>K</td>\n",
       "      <td>True</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>vwc</td>\n",
       "      <td>user-group</td>\n",
       "      <td>pay when scheme fails</td>\n",
       "      <td>on failure</td>\n",
       "      <td>salty</td>\n",
       "      <td>salty</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  amount_tsh date_recorded                  funder  gps_height  \\\n",
       "0    454.0        50.0    27/02/2013                    Dmdd      2092.0   \n",
       "1    510.0         0.0    17/03/2011                    Cmsr         0.0   \n",
       "2  14146.0         0.0    10/07/2011                    Kkkt         0.0   \n",
       "3  47410.0         0.0    12/04/2011  Government Of Tanzania         0.0   \n",
       "4   1288.0       300.0    05/04/2011                      Ki      1023.0   \n",
       "\n",
       "  installer  longitude  latitude                 wpt_name  num_private  \\\n",
       "0      DMDD  35.426020 -4.227446                    Narmo          0.0   \n",
       "1      Gove  35.510074 -5.724555                   Lukali          0.0   \n",
       "2      KKKT  32.499866 -9.081222                 Mahakama          0.0   \n",
       "3       DWE  34.060484 -8.830208  Shule Ya Msingi Chosi A          0.0   \n",
       "4        Ki  37.032690 -6.040787                Kwa Mjowe          0.0   \n",
       "\n",
       "         basin    subvillage    region  region_code  district_code      lga  \\\n",
       "0     Internal  Bashnet Kati   Manyara         21.0            1.0   Babati   \n",
       "1     Internal        Lukali    Dodoma          1.0            6.0     Bahi   \n",
       "2   Lake Rukwa   Chawalikozi     Mbeya         12.0            6.0    Mbozi   \n",
       "3       Rufiji       Shuleni     Mbeya         12.0            7.0  Mbarali   \n",
       "4  Wami / Ruvu      Ngholong  Morogoro          5.0            1.0   Kilosa   \n",
       "\n",
       "       ward  population  public_meeting              recorded_by  \\\n",
       "0  Bashinet       160.0            True  GeoData Consultants Ltd   \n",
       "1   Lamaiti         0.0            True  GeoData Consultants Ltd   \n",
       "2  Ndalambo         0.0            True  GeoData Consultants Ltd   \n",
       "3   Chimala         0.0            True  GeoData Consultants Ltd   \n",
       "4  Chakwale       120.0            True  GeoData Consultants Ltd   \n",
       "\n",
       "  scheme_management scheme_name  permit  construction_year extraction_type  \\\n",
       "0       Water Board           K    True             1998.0         gravity   \n",
       "1               VWC           K    True                0.0   india mark ii   \n",
       "2               VWC           K   False                0.0           other   \n",
       "3               VWC           K    True                0.0         gravity   \n",
       "4               VWC           K    True             1997.0           other   \n",
       "\n",
       "  extraction_type_group extraction_type_class   management management_group  \\\n",
       "0               gravity               gravity  water board       user-group   \n",
       "1         india mark ii              handpump          vwc       user-group   \n",
       "2                 other                 other          vwc       user-group   \n",
       "3               gravity               gravity          vwc       user-group   \n",
       "4                 other                 other          vwc       user-group   \n",
       "\n",
       "                 payment payment_type water_quality quality_group  \\\n",
       "0         pay per bucket   per bucket          soft          good   \n",
       "1              never pay    never pay          soft          good   \n",
       "2              never pay    never pay          soft          good   \n",
       "3            pay monthly      monthly          soft          good   \n",
       "4  pay when scheme fails   on failure         salty         salty   \n",
       "\n",
       "       quantity quantity_group        source   source_type source_class  \\\n",
       "0  insufficient   insufficient        spring        spring  groundwater   \n",
       "1        enough         enough  shallow well  shallow well  groundwater   \n",
       "2        enough         enough  shallow well  shallow well  groundwater   \n",
       "3  insufficient   insufficient         river    river/lake      surface   \n",
       "4        enough         enough  shallow well  shallow well  groundwater   \n",
       "\n",
       "      waterpoint_type waterpoint_type_group  \n",
       "0  communal standpipe    communal standpipe  \n",
       "1           hand pump             hand pump  \n",
       "2               other                 other  \n",
       "3  communal standpipe    communal standpipe  \n",
       "4               other                 other  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV, cross_val_predict\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, SelectFromModel\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, accuracy_score, f1_score\n",
    "\n",
    "# Configuración para mostrar todas las columnas en pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Carga de datos (Asegúrate de cambiar el nombre del archivo al que tengáis en el grupo)\n",
    "# Usamos solo el TRAIN. El TEST está prohibido mirarlo hasta el final del proyecto.\n",
    "X_train = pd.read_csv(\"X_train_prep.csv\") \n",
    "y_train = pd.read_csv(\"y_train.csv\").values.ravel() # .ravel() para que sea un array 1D\n",
    "\n",
    "print(\"Dimensiones del Training:\", X_train.shape)\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145d13da",
   "metadata": {},
   "source": [
    "## Preprocesamiento para ambos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6866fc68",
   "metadata": {},
   "source": [
    "**Tratamiento de Anomalías de Dominio (Valores Perdidos Encubiertos)**\n",
    "\n",
    "Comenzamos realizando un análisis semántico de los valores numéricos. Hemos detectado que variables como construction_year contienen valores de 0, lo cual carece de sentido físico (año 0) y representa una codificación de valor perdido. Dado que los imputadores estándar tratarían el 0 como un valor numérico válido (sesgando gravemente las medias y distancias en kNN), procedemos a transformar explícitamente estos ceros a NaN. De esta forma, los imputadores posteriores (KNNImputer y SimpleImputer) podrán detectar el hueco y rellenarlo con una estimación estadística coherente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8ae874",
   "metadata": {},
   "source": [
    "_Nota sobre el Conjunto de Test:_ Esta transformación de ceros a NaNs es una corrección determinista basada en el conocimiento del dominio. Por tanto, deberá replicarse idénticamente sobre el conjunto de test (X_test) en la fase final de evaluación, antes de introducir los datos en el pipeline entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f8e77b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable 'construction_year': convirtiendo 16503 ceros a NaN.\n",
      "Variable 'gps_height': convirtiendo 16275 ceros a NaN.\n",
      "\n",
      "Nulos tras corrección de ceros:\n",
      "construction_year    16503\n",
      "gps_height           16275\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Lista de columnas donde el 0 no tiene sentido físico (NaN encubiertos)\n",
    "# construction_year: no puede ser 0.\n",
    "# gps_height: asumimos que 0 es un error de medición (o falta de dato) en este contexto.\n",
    "cols_with_zeros_as_nan = ['construction_year', 'gps_height']\n",
    "\n",
    "# Reemplazamos 0 por NaN solo en estas columnas\n",
    "for col in cols_with_zeros_as_nan:\n",
    "    # Contamos cuántos ceros hay para documentarlo\n",
    "    n_zeros = (X_train[col] == 0).sum()\n",
    "    print(f\"Variable '{col}': convirtiendo {n_zeros} ceros a NaN.\")\n",
    "    # Transformación\n",
    "    X_train[col] = X_train[col].replace(0, np.nan)\n",
    "\n",
    "# Verificación\n",
    "print(\"\\nNulos tras corrección de ceros:\")\n",
    "print(X_train[cols_with_zeros_as_nan].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47e66e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases detectadas: ['functional' 'functional needs repair' 'non functional']\n",
      "Mapeo: {'functional': 0, 'functional needs repair': 1, 'non functional': 2}\n"
     ]
    }
   ],
   "source": [
    "# Codificación de la variable objetivo (y_train)\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "\n",
    "# Guardamos el mapeo para saber qué es qué en la presentación\n",
    "print(\"Clases detectadas:\", le.classes_)\n",
    "print(\"Mapeo:\", dict(zip(le.classes_, range(len(le.classes_)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70773492",
   "metadata": {},
   "source": [
    "Procedemos a la codificación de la variable objetivo (y_train). Dado que las etiquetas originales son categóricas ('functional', etc.), aplicamos un LabelEncoder para transformarlas en valores numéricos. Este paso es fundamental para asegurar la compatibilidad con los algoritmos y el cálculo correcto de las métricas de error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bced4b",
   "metadata": {},
   "source": [
    "Antes de aplicar los algoritmos, realizamos una segregación de atributos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25e3f078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables Numéricas: 10\n",
      "Variables Categóricas de Baja Cardinalidad (<20): 21\n",
      "Variables Categóricas de Alta Cardinalidad (>20): 9\n",
      "Variables de alta cardinalidad: ['date_recorded', 'funder', 'installer', 'wpt_name', 'subvillage', 'region', 'lga', 'ward', 'scheme_name']\n"
     ]
    }
   ],
   "source": [
    "# Variables Numéricas:\n",
    "num_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Variables Categóricas:\n",
    "cat_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Detectamos columnas con demasiadas categorías únicas (> 20) que podrían ralentizar kNN\n",
    "high_card_cols = [col for col in cat_cols if X_train[col].nunique() > 20]\n",
    "low_card_cols = [col for col in cat_cols if X_train[col].nunique() <= 20]\n",
    "\n",
    "print(f\"Variables Numéricas: {len(num_cols)}\")\n",
    "print(f\"Variables Categóricas de Baja Cardinalidad (<20): {len(low_card_cols)}\")\n",
    "print(f\"Variables Categóricas de Alta Cardinalidad (>20): {len(high_card_cols)}\")\n",
    "print(\"Variables de alta cardinalidad:\", high_card_cols[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1d77a5",
   "metadata": {},
   "source": [
    "Hemos detectado variables categóricas con una alta cardinalidad (muchos valores únicos). Esto es crítico para el algoritmo kNN, ya que la codificación masiva de estas variables aumentaría drásticamente la dimensionalidad (la 'maldición de la dimensionalidad'), dispersando los vecinos y degradando el rendimiento. Por tanto, aplicaremos estrategias de codificación diferenciadas según el algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54e22424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones antes de limpiar outliers: (47520, 40)\n",
      "Dimensiones tras limpiar outliers: (45144, 40)\n",
      "Se han eliminado 2376 instancias ruidosas.\n"
     ]
    }
   ],
   "source": [
    "# --- LIMPIEZA DE OUTLIERS CON ISOLATION FOREST ---\n",
    "print(f\"Dimensiones antes de limpiar outliers: {X_train.shape}\")\n",
    "\n",
    "# Contamination=0.05 implica que asumimos un 5% de ruido/errores\n",
    "iso = IsolationForest(contamination=0.05, random_state=42, n_jobs=-1)\n",
    "\n",
    "# 2. Ajuste temporal: IsolationForest no tolera NaNs, imputamos temporalmente solo para detectar el ruido\n",
    "# Usamos solo variables numéricas para detectar anomalías geométricas\n",
    "X_num_temp = SimpleImputer(strategy='median').fit_transform(X_train[num_cols])\n",
    "outliers_pred = iso.fit_predict(X_num_temp) # Devuelve -1 (outlier) o 1 (normal)\n",
    "\n",
    "# 3. Filtrado: Nos quedamos solo con los datos normales (1)\n",
    "mask_clean = outliers_pred == 1\n",
    "X_train = X_train[mask_clean].reset_index(drop=True)\n",
    "y_train = y_train[mask_clean] # Filtramos la Y para mantener la coherencia\n",
    "\n",
    "print(f\"Dimensiones tras limpiar outliers: {X_train.shape}\")\n",
    "print(f\"Se han eliminado {(~mask_clean).sum()} instancias ruidosas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa27b2e",
   "metadata": {},
   "source": [
    "Aplicamos una etapa de saneamiento de datos mediante el algoritmo Isolation Forest. Esta técnica nos permite detectar y eliminar instancias con 'ruido de atributo' (valores anómalos). Eliminamos aproximadamente un 5% de las observaciones más atípicas. Esto es crítico para el algoritmo kNN, altamente sensible a outliers, pero también beneficia al Random Forest al reducir la complejidad innecesaria, asegurando que los modelos aprendan patrones representativos y no errores de recolección."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21751dc9",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbb63ce",
   "metadata": {},
   "source": [
    "## Preprocesamiento para KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42d9cb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Numérico:\n",
    "# Imputación: Usamos KNNImputer para estimar valores perdidos basándonos en similitud.\n",
    "# Escalado: StandardScaler es OBLIGATORIO en kNN para que las distancias sean comparables.\n",
    "num_transformer_knn = Pipeline(steps=[\n",
    "    ('imputer', KNNImputer(n_neighbors=5)), \n",
    "    ('scaler', StandardScaler()) \n",
    "])\n",
    "\n",
    "# Pipeline Categórico (Baja Cardinalidad):\n",
    "# Imputación: Rellenamos con la moda (most_frequent).\n",
    "# Codificación: OneHotEncoder para no imponer orden arbitrario, handle_unknown='ignore' por si en validación aparece una categoría nueva.\n",
    "cat_transformer_low_knn = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Pipeline Categórico (Alta Cardinalidad):\n",
    "# TargetEncoder para variables con miles de categorías para no generar miles de columnas nuevas con OneHotEncoder\n",
    "cat_transformer_high_knn = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', TargetEncoder(handle_unknown='value'))\n",
    "])\n",
    "\n",
    "# Unimos todo en el ColumnTransformer específico para kNN\n",
    "preprocessor_knn = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer_knn, num_cols),\n",
    "        ('cat_low', cat_transformer_low_knn, low_card_cols),\n",
    "        ('cat_high', cat_transformer_high_knn, high_card_cols)\n",
    "    ],\n",
    "    remainder='drop' # Lo que no esté aquí, se borra\n",
    ")\n",
    "\n",
    "# Pipeline FINAL KNN con Selección de Características\n",
    "knn_pipeline_final = Pipeline([\n",
    "    ('preprocessor', preprocessor_knn),\n",
    "    ('selector', SelectKBest(mutual_info_classif, k=30)), # Selecciona las 30 mejores\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3b1912",
   "metadata": {},
   "source": [
    "Dado que kNN se basa en distancias euclídeas, hemos aplicado StandardScaler a las variables numéricas para evitar que atributos con grandes magnitudes dominen la decisión. Para los valores perdidos, utilizamos KNNImputer, aprovechando la propia naturaleza del algoritmo para imputaciones más precisas. Las variables categóricas se han separado: las de baja cardinalidad usan One-Hot Encoding para evitar falsos órdenes, mientras que las de alta cardinalidad usan Target Encoding para mantener la eficiencia computacional. Además, integramos una etapa de Selección de Características (Filter) basada en Información Mutua (SelectKBest), forzando al algoritmo a utilizar solo las 30 variables más discriminantes, eliminando ruido que degradaría el cálculo de distancias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a94c5590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Prueba de transformación para kNN ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Verificación rápida de la transformación kNN\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- Prueba de transformación para kNN ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m X_knn_processed = \u001b[43mpreprocessor_knn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mForma original: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mForma tras preprocesamiento kNN: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_knn_processed.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/sklearn/utils/_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/sklearn/compose/_column_transformer.py:996\u001b[39m, in \u001b[36mColumnTransformer.fit_transform\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    993\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    994\u001b[39m     routed_params = \u001b[38;5;28mself\u001b[39m._get_empty_routing()\n\u001b[32m--> \u001b[39m\u001b[32m996\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_func_on_transformers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_fit_transform_one\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumn_as_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result:\n\u001b[32m   1005\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_fitted_transformers([])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/sklearn/compose/_column_transformer.py:897\u001b[39m, in \u001b[36mColumnTransformer._call_func_on_transformers\u001b[39m\u001b[34m(self, X, y, func, column_as_labels, routed_params)\u001b[39m\n\u001b[32m    885\u001b[39m             extra_args = {}\n\u001b[32m    886\u001b[39m         jobs.append(\n\u001b[32m    887\u001b[39m             delayed(func)(\n\u001b[32m    888\u001b[39m                 transformer=clone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[32m   (...)\u001b[39m\u001b[32m    894\u001b[39m             )\n\u001b[32m    895\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    900\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mExpected 2D array, got 1D array instead\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/joblib/parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/joblib/parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/sklearn/utils/parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/sklearn/pipeline.py:1540\u001b[39m, in \u001b[36m_fit_transform_one\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1539\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m         res = \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_transform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1541\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1542\u001b[39m         res = transformer.fit(X, y, **params.get(\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, {})).transform(\n\u001b[32m   1543\u001b[39m             X, **params.get(\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m   1544\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/sklearn/pipeline.py:719\u001b[39m, in \u001b[36mPipeline.fit_transform\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    680\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Fit the model and transform with the final estimator.\u001b[39;00m\n\u001b[32m    681\u001b[39m \n\u001b[32m    682\u001b[39m \u001b[33;03mFit all the transformers one after the other and sequentially transform\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    716\u001b[39m \u001b[33;03m    Transformed samples.\u001b[39;00m\n\u001b[32m    717\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    718\u001b[39m routed_params = \u001b[38;5;28mself\u001b[39m._check_method_params(method=\u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m, props=params)\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m Xt = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m last_step = \u001b[38;5;28mself\u001b[39m._final_estimator\n\u001b[32m    722\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[33m\"\u001b[39m\u001b[33mPipeline\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.steps) - \u001b[32m1\u001b[39m)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/sklearn/pipeline.py:589\u001b[39m, in \u001b[36mPipeline._fit\u001b[39m\u001b[34m(self, X, y, routed_params, raw_params)\u001b[39m\n\u001b[32m    582\u001b[39m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[32m    583\u001b[39m step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    584\u001b[39m     step_idx=step_idx,\n\u001b[32m    585\u001b[39m     step_params=routed_params[name],\n\u001b[32m    586\u001b[39m     all_params=raw_params,\n\u001b[32m    587\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m X, fitted_transformer = \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPipeline\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[32m    600\u001b[39m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[32m    601\u001b[39m \u001b[38;5;28mself\u001b[39m.steps[step_idx] = (name, fitted_transformer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/joblib/memory.py:326\u001b[39m, in \u001b[36mNotMemorizedFunc.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/sklearn/pipeline.py:1540\u001b[39m, in \u001b[36m_fit_transform_one\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1539\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m         res = \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_transform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1541\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1542\u001b[39m         res = transformer.fit(X, y, **params.get(\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, {})).transform(\n\u001b[32m   1543\u001b[39m             X, **params.get(\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m   1544\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/sklearn/utils/_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/sklearn/base.py:897\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    894\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, **fit_params).transform(X)\n\u001b[32m    895\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    896\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/sklearn/utils/_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/sklearn/impute/_knn.py:376\u001b[39m, in \u001b[36mKNNImputer.transform\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;66;03m# process in fixed-memory chunks\u001b[39;00m\n\u001b[32m    368\u001b[39m gen = pairwise_distances_chunked(\n\u001b[32m    369\u001b[39m     X[row_missing_idx, :],\n\u001b[32m    370\u001b[39m     \u001b[38;5;28mself\u001b[39m._fit_X,\n\u001b[32m   (...)\u001b[39m\u001b[32m    374\u001b[39m     reduce_func=process_chunk,\n\u001b[32m    375\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# process_chunk modifies X in place. No return value.\u001b[39;49;00m\n\u001b[32m    378\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mpass\u001b[39;49;00m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.keep_empty_features:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/sklearn/metrics/pairwise.py:2240\u001b[39m, in \u001b[36mpairwise_distances_chunked\u001b[39m\u001b[34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[39m\n\u001b[32m   2238\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2239\u001b[39m     X_chunk = X[sl]\n\u001b[32m-> \u001b[39m\u001b[32m2240\u001b[39m D_chunk = \u001b[43mpairwise_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2241\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS.get(\n\u001b[32m   2242\u001b[39m     metric, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2243\u001b[39m ) \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[32m   2244\u001b[39m     \u001b[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[32m   2245\u001b[39m     \u001b[38;5;66;03m# i.e. \"l2\"\u001b[39;00m\n\u001b[32m   2246\u001b[39m     D_chunk.flat[sl.start :: _num_samples(X) + \u001b[32m1\u001b[39m] = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/sklearn/metrics/pairwise.py:2476\u001b[39m, in \u001b[36mpairwise_distances\u001b[39m\u001b[34m(X, Y, metric, n_jobs, force_all_finite, ensure_all_finite, **kwds)\u001b[39m\n\u001b[32m   2473\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m distance.squareform(distance.pdist(X, metric=metric, **kwds))\n\u001b[32m   2474\u001b[39m     func = partial(distance.cdist, metric=metric, **kwds)\n\u001b[32m-> \u001b[39m\u001b[32m2476\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parallel_pairwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/sklearn/metrics/pairwise.py:1960\u001b[39m, in \u001b[36m_parallel_pairwise\u001b[39m\u001b[34m(X, Y, func, n_jobs, **kwds)\u001b[39m\n\u001b[32m   1957\u001b[39m X, Y, dtype = _return_float_dtype(X, Y)\n\u001b[32m   1959\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) == \u001b[32m1\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1960\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1962\u001b[39m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[32m   1963\u001b[39m fd = delayed(_dist_wrapper)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:191\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/sklearn/metrics/pairwise.py:552\u001b[39m, in \u001b[36mnan_euclidean_distances\u001b[39m\u001b[34m(X, Y, squared, missing_values, copy)\u001b[39m\n\u001b[32m    549\u001b[39m X[missing_X] = \u001b[32m0\u001b[39m\n\u001b[32m    550\u001b[39m Y[missing_Y] = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m distances = \u001b[43meuclidean_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[38;5;66;03m# Adjust distances for missing values\u001b[39;00m\n\u001b[32m    555\u001b[39m XX = X * X\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:191\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/sklearn/metrics/pairwise.py:388\u001b[39m, in \u001b[36meuclidean_distances\u001b[39m\u001b[34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[39m\n\u001b[32m    382\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m Y_norm_squared.shape != (\u001b[32m1\u001b[39m, Y.shape[\u001b[32m0\u001b[39m]):\n\u001b[32m    383\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    384\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIncompatible dimensions for Y of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    385\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mY_norm_squared of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    386\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_euclidean_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/sklearn/metrics/pairwise.py:428\u001b[39m, in \u001b[36m_euclidean_distances\u001b[39m\u001b[34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[39m\n\u001b[32m    425\u001b[39m     distances += XX\n\u001b[32m    426\u001b[39m     distances += YY\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m xp_zero = \u001b[43mxp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    429\u001b[39m distances = _modify_in_place_if_numpy(\n\u001b[32m    430\u001b[39m     xp, xp.maximum, distances, xp_zero, out=distances\n\u001b[32m    431\u001b[39m )\n\u001b[32m    433\u001b[39m \u001b[38;5;66;03m# Ensure that distances between vectors and themselves are set to 0.0.\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[38;5;66;03m# This may not be the case due to floating point rounding errors.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/sklearn/externals/array_api_compat/numpy/_aliases.py:89\u001b[39m, in \u001b[36masarray\u001b[39m\u001b[34m(obj, dtype, device, copy, **kwargs)\u001b[39m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# asarray also adds the copy keyword, which is not present in numpy 1.0.\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[38;5;66;03m# asarray() is different enough between numpy, cupy, and dask, the logic\u001b[39;00m\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# complicated enough that it's easier to define it separately for each module\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# rather than trying to combine everything into one function in common/\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34masarray\u001b[39m(\n\u001b[32m     90\u001b[39m     obj: Array | \u001b[38;5;28mcomplex\u001b[39m | NestedSequence[\u001b[38;5;28mcomplex\u001b[39m] | SupportsBufferProtocol,\n\u001b[32m     91\u001b[39m     /,\n\u001b[32m     92\u001b[39m     *,\n\u001b[32m     93\u001b[39m     dtype: DType | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     94\u001b[39m     device: Device | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     95\u001b[39m     copy: _Copy | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     96\u001b[39m     **kwargs: Any,\n\u001b[32m     97\u001b[39m ) -> Array:\n\u001b[32m     98\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[33;03m    Array API compatibility wrapper for asarray().\u001b[39;00m\n\u001b[32m    100\u001b[39m \n\u001b[32m    101\u001b[39m \u001b[33;03m    See the corresponding documentation in the array library and/or the array API\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[33;03m    specification for more details.\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    104\u001b[39m     _helpers._check_device(np, device)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Verificación rápida de la transformación kNN\n",
    "print(\"--- Prueba de transformación para kNN ---\")\n",
    "X_knn_processed = preprocessor_knn.fit_transform(X_train, y_train)\n",
    "print(f\"Forma original: {X_train.shape}\")\n",
    "print(f\"Forma tras preprocesamiento kNN: {X_knn_processed.shape}\")\n",
    "# Las columnas aumentan por el OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a486f5aa",
   "metadata": {},
   "source": [
    "Como control de calidad, verificamos la dimensionalidad resultante del preprocesamiento aplicado a kNN. Observamos que este enfoque expande el espacio de características debido a la codificación binaria (One-Hot), lo cual es coherente con las necesidades del algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3c5a6ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ColumnTransformer' object has no attribute 'transformers_'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#Visualización tras el preprocesado\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m cols_knn = \u001b[43mpreprocessor_knn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_feature_names_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m df_knn_viz = pd.DataFrame(X_knn_processed, columns=cols_knn)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTamaño del dataset KNN: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_knn_viz.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/sklearn/compose/_column_transformer.py:627\u001b[39m, in \u001b[36mColumnTransformer.get_feature_names_out\u001b[39m\u001b[34m(self, input_features)\u001b[39m\n\u001b[32m    625\u001b[39m \u001b[38;5;66;03m# List of tuples (name, feature_names_out)\u001b[39;00m\n\u001b[32m    626\u001b[39m transformer_with_feature_names_out = []\n\u001b[32m--> \u001b[39m\u001b[32m627\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfitted\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumn_as_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskip_empty_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskip_drop\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_names_out\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_feature_name_out_for_transformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_features\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeature_names_out\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/sklearn/compose/_column_transformer.py:465\u001b[39m, in \u001b[36mColumnTransformer._iter\u001b[39m\u001b[34m(self, fitted, column_as_labels, skip_drop, skip_empty_columns)\u001b[39m\n\u001b[32m    434\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    435\u001b[39m \u001b[33;03mGenerate (name, trans, columns, weight) tuples.\u001b[39;00m\n\u001b[32m    436\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    462\u001b[39m \u001b[33;03m    - weight : the weight of the transformer\u001b[39;00m\n\u001b[32m    463\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fitted:\n\u001b[32m--> \u001b[39m\u001b[32m465\u001b[39m     transformers = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformers_\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    467\u001b[39m     \u001b[38;5;66;03m# interleave the validated column specifiers\u001b[39;00m\n\u001b[32m    468\u001b[39m     transformers = [\n\u001b[32m    469\u001b[39m         (name, trans, column)\n\u001b[32m    470\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m (name, trans, _), column \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m.transformers, \u001b[38;5;28mself\u001b[39m._columns)\n\u001b[32m    471\u001b[39m     ]\n",
      "\u001b[31mAttributeError\u001b[39m: 'ColumnTransformer' object has no attribute 'transformers_'"
     ]
    }
   ],
   "source": [
    "#Visualización tras el preprocesado\n",
    "cols_knn = preprocessor_knn.get_feature_names_out()\n",
    "df_knn_viz = pd.DataFrame(X_knn_processed, columns=cols_knn)\n",
    "print(f\"Tamaño del dataset KNN: {df_knn_viz.shape}\")\n",
    "display(df_knn_viz.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fb5635",
   "metadata": {},
   "source": [
    "## Ajuste de hiperparámetros para KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e59cc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando ajuste de kNN...\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END classifier__metric=euclidean, classifier__n_neighbors=5;, score=0.757 total time= 1.9min\n",
      "[CV 3/5] END classifier__metric=euclidean, classifier__n_neighbors=5;, score=0.764 total time= 2.0min\n",
      "[CV 1/5] END classifier__metric=euclidean, classifier__n_neighbors=5;, score=0.757 total time= 2.0min\n",
      "[CV 4/5] END classifier__metric=euclidean, classifier__n_neighbors=5;, score=0.758 total time= 1.9min\n",
      "[CV 5/5] END classifier__metric=euclidean, classifier__n_neighbors=5;, score=0.749 total time= 2.0min\n",
      "[CV 1/5] END classifier__metric=euclidean, classifier__n_neighbors=7;, score=0.762 total time= 2.0min\n",
      "[CV 2/5] END classifier__metric=euclidean, classifier__n_neighbors=7;, score=0.761 total time= 1.9min\n",
      "[CV 3/5] END classifier__metric=euclidean, classifier__n_neighbors=7;, score=0.769 total time= 2.0min\n",
      "[CV 4/5] END classifier__metric=euclidean, classifier__n_neighbors=7;, score=0.763 total time= 2.0min\n",
      "[CV 5/5] END classifier__metric=euclidean, classifier__n_neighbors=7;, score=0.759 total time= 2.1min\n",
      "[CV 1/5] END classifier__metric=euclidean, classifier__n_neighbors=9;, score=0.760 total time= 2.1min\n",
      "[CV 2/5] END classifier__metric=euclidean, classifier__n_neighbors=9;, score=0.760 total time= 2.1min\n",
      "[CV 3/5] END classifier__metric=euclidean, classifier__n_neighbors=9;, score=0.766 total time= 2.2min\n",
      "[CV 4/5] END classifier__metric=euclidean, classifier__n_neighbors=9;, score=0.758 total time= 2.3min\n",
      "[CV 5/5] END classifier__metric=euclidean, classifier__n_neighbors=9;, score=0.755 total time= 2.2min\n",
      "[CV 1/5] END classifier__metric=manhattan, classifier__n_neighbors=5;, score=0.766 total time= 2.3min\n",
      "[CV 2/5] END classifier__metric=manhattan, classifier__n_neighbors=5;, score=0.767 total time= 2.3min\n",
      "[CV 3/5] END classifier__metric=manhattan, classifier__n_neighbors=5;, score=0.774 total time= 2.3min\n",
      "[CV 4/5] END classifier__metric=manhattan, classifier__n_neighbors=5;, score=0.774 total time= 2.2min\n",
      "[CV 1/5] END classifier__metric=manhattan, classifier__n_neighbors=7;, score=0.768 total time= 2.2min\n",
      "[CV 5/5] END classifier__metric=manhattan, classifier__n_neighbors=5;, score=0.765 total time= 2.2min\n",
      "[CV 2/5] END classifier__metric=manhattan, classifier__n_neighbors=7;, score=0.773 total time= 2.0min\n",
      "[CV 3/5] END classifier__metric=manhattan, classifier__n_neighbors=7;, score=0.777 total time= 2.0min\n",
      "[CV 4/5] END classifier__metric=manhattan, classifier__n_neighbors=7;, score=0.774 total time= 2.1min\n",
      "[CV 5/5] END classifier__metric=manhattan, classifier__n_neighbors=7;, score=0.766 total time= 2.0min\n",
      "[CV 2/5] END classifier__metric=manhattan, classifier__n_neighbors=9;, score=0.773 total time= 2.0min\n",
      "[CV 1/5] END classifier__metric=manhattan, classifier__n_neighbors=9;, score=0.774 total time= 2.0min\n",
      "[CV 3/5] END classifier__metric=manhattan, classifier__n_neighbors=9;, score=0.772 total time= 2.1min\n",
      "[CV 5/5] END classifier__metric=manhattan, classifier__n_neighbors=9;, score=0.765 total time= 2.1min\n",
      "[CV 4/5] END classifier__metric=manhattan, classifier__n_neighbors=9;, score=0.771 total time= 2.1min\n",
      "Mejor Accuracy kNN (CV): 0.7716\n",
      "Mejores Parámetros kNN: {'classifier__metric': 'manhattan', 'classifier__n_neighbors': 7}\n"
     ]
    }
   ],
   "source": [
    "# 1. Definimos la rejilla de parámetros\n",
    "# Nota: Usamos el prefijo 'classifier__' porque el kNN está dentro de un Pipeline.\n",
    "# También ajustamos 'selector__k' para ver si es mejor usar 20, 30 o 40 variables.\n",
    "param_grid_knn = {\n",
    "    'classifier__n_neighbors': [5, 7, 9], # La K (número de vecinos)\n",
    "    'classifier__metric': ['euclidean', 'manhattan'] # Geometría del espacio\n",
    "}\n",
    "\n",
    "# 2. Configuración del GridSearch\n",
    "# cv=5: Validación cruzada de 5 pliegues (StratifiedKFold por defecto en clasificación)\n",
    "# scoring='accuracy': Métrica principal (puedes cambiar a 'f1_macro' si prefieres)\n",
    "# n_jobs=-1: Usa todos los núcleos del procesador (vital porque kNN es lento)\n",
    "grid_knn = GridSearchCV(\n",
    "    estimator=knn_pipeline_final,\n",
    "    param_grid=param_grid_knn,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=3,\n",
    "    verbose=3\n",
    ")\n",
    "\n",
    "# 3. Ejecución (Esto puede tardar unos minutos)\n",
    "print(\"Iniciando ajuste de kNN...\")\n",
    "grid_knn.fit(X_train, y_train)\n",
    "\n",
    "# 4. Resultados\n",
    "print(f\"Mejor Accuracy kNN (CV): {grid_knn.best_score_:.4f}\")\n",
    "print(f\"Mejores Parámetros kNN: {grid_knn.best_params_}\")\n",
    "\n",
    "# Guardamos el mejor modelo\n",
    "best_knn_model = grid_knn.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce64669c",
   "metadata": {},
   "source": [
    "Para el algoritmo k-Nearest Neighbors, implementamos una búsqueda exhaustiva de hiperparámetros (GridSearchCV) con validación cruzada de 5 folds. El objetivo fue optimizar conjuntamente la dimensionalidad del espacio (ajustando el número de características seleccionadas por Información Mutua) y la topología del clasificador. Exploramos distintas métricas de distancia (Euclídea vs Manhattan), esquemas de votación (uniforme vs ponderada por distancia) y el factor K de vecindad. Este enfoque asegura que el modelo final no solo memoriza el entrenamiento, sino que generaliza correctamente la estructura local de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169f866a",
   "metadata": {},
   "source": [
    "# BAGGING (Random Forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0536e914",
   "metadata": {},
   "source": [
    "## Preprocesamiento para bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd5b2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Numérico:\n",
    "# Imputación: SimpleImputer (media/mediana) es suficiente para árboles.\n",
    "# El escalado no es necesario en árboles.\n",
    "num_transformer_rf = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "# Pipeline Categórico (Todo junto):\n",
    "# Los árboles manejan bien OrdinalEncoder. OneHotEncoder en variables con muchas categorías puede generar árboles muy profundos y dispersos.\n",
    "cat_transformer_rf = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "# Unimos todo en el ColumnTransformer específico para RF\n",
    "preprocessor_rf = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer_rf, num_cols),\n",
    "        ('cat', cat_transformer_rf, cat_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Pipeline FINAL RF con Selección Embedded\n",
    "rf_pipeline_final = Pipeline([\n",
    "    ('preprocessor', preprocessor_rf),\n",
    "    ('selector', SelectFromModel(RandomForestClassifier(n_estimators=50, random_state=42), threshold='median')),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2e9420",
   "metadata": {},
   "source": [
    "Para el algoritmo de ensamblado Bagging (Random Forest), la estrategia cambia radicalmente. Al ser un método basado en árboles de decisión, no requiere normalización de datos ya que realiza cortes ortogonales en el espacio de características. Hemos optado por una imputación estadística simple y un Ordinal Encoding para todas las variables categóricas. Esta codificación es más eficiente para modelos basados en árboles que el One-Hot Encoding, ya que permite al modelo realizar particiones agrupando categorías numéricamente cercanas sin aumentar la dispersión de los datos. Además, añadimos una selección de características tipo 'Embedded' (SelectFromModel), que entrena un RandomForest preliminar para descartar variables con baja importancia antes del entrenamiento final, reduciendo el riesgo de overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4285e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Prueba de transformación para Random Forest ---\n",
      "Forma original: (45144, 40)\n",
      "Forma tras preprocesamiento RF: (45144, 40)\n"
     ]
    }
   ],
   "source": [
    "# Verificación rápida de la transformación RF\n",
    "print(\"\\n--- Prueba de transformación para Random Forest ---\")\n",
    "X_rf_processed = preprocessor_rf.fit_transform(X_train)\n",
    "print(f\"Forma original: {X_train.shape}\")\n",
    "print(f\"Forma tras preprocesamiento RF: {X_rf_processed.shape}\")\n",
    "# La dimensionalidad se mantiene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b126ee1",
   "metadata": {},
   "source": [
    "Analizando la dimensionalidad resultante del preprocesamiento, observamos que, en este caso, la preparación para Random Forest mantiene una estructura de datos más compacta, confirmando que la representación elegida está optimizada para aprovechar la naturaleza matemática y la capacidad de particionado de este tipo de algoritmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d9ac7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset RF: (45144, 40)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__id</th>\n",
       "      <th>num__amount_tsh</th>\n",
       "      <th>num__gps_height</th>\n",
       "      <th>num__longitude</th>\n",
       "      <th>num__latitude</th>\n",
       "      <th>num__num_private</th>\n",
       "      <th>num__region_code</th>\n",
       "      <th>num__district_code</th>\n",
       "      <th>num__population</th>\n",
       "      <th>num__construction_year</th>\n",
       "      <th>cat__date_recorded</th>\n",
       "      <th>cat__funder</th>\n",
       "      <th>cat__installer</th>\n",
       "      <th>cat__wpt_name</th>\n",
       "      <th>cat__basin</th>\n",
       "      <th>cat__subvillage</th>\n",
       "      <th>cat__region</th>\n",
       "      <th>cat__lga</th>\n",
       "      <th>cat__ward</th>\n",
       "      <th>cat__public_meeting</th>\n",
       "      <th>cat__recorded_by</th>\n",
       "      <th>cat__scheme_management</th>\n",
       "      <th>cat__scheme_name</th>\n",
       "      <th>cat__permit</th>\n",
       "      <th>cat__extraction_type</th>\n",
       "      <th>cat__extraction_type_group</th>\n",
       "      <th>cat__extraction_type_class</th>\n",
       "      <th>cat__management</th>\n",
       "      <th>cat__management_group</th>\n",
       "      <th>cat__payment</th>\n",
       "      <th>cat__payment_type</th>\n",
       "      <th>cat__water_quality</th>\n",
       "      <th>cat__quality_group</th>\n",
       "      <th>cat__quantity</th>\n",
       "      <th>cat__quantity_group</th>\n",
       "      <th>cat__source</th>\n",
       "      <th>cat__source_type</th>\n",
       "      <th>cat__source_class</th>\n",
       "      <th>cat__waterpoint_type</th>\n",
       "      <th>cat__waterpoint_type_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>454.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2092.0</td>\n",
       "      <td>35.426020</td>\n",
       "      <td>-4.227446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>24839.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>510.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>35.510074</td>\n",
       "      <td>-5.724555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>20890.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7203.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>830.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14146.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>32.499866</td>\n",
       "      <td>-9.081222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>615.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>21231.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1287.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1519.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>551.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47410.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>34.060484</td>\n",
       "      <td>-8.830208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>27339.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15231.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1288.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>37.032690</td>\n",
       "      <td>-6.040787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>579.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>12815.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12849.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num__id  num__amount_tsh  num__gps_height  num__longitude  num__latitude  \\\n",
       "0    454.0             50.0           2092.0       35.426020      -4.227446   \n",
       "1    510.0              0.0           1213.0       35.510074      -5.724555   \n",
       "2  14146.0              0.0           1213.0       32.499866      -9.081222   \n",
       "3  47410.0              0.0           1213.0       34.060484      -8.830208   \n",
       "4   1288.0            300.0           1023.0       37.032690      -6.040787   \n",
       "\n",
       "   num__num_private  num__region_code  num__district_code  num__population  \\\n",
       "0               0.0              21.0                 1.0            160.0   \n",
       "1               0.0               1.0                 6.0              0.0   \n",
       "2               0.0              12.0                 6.0              0.0   \n",
       "3               0.0              12.0                 7.0              0.0   \n",
       "4               0.0               5.0                 1.0            120.0   \n",
       "\n",
       "   num__construction_year  cat__date_recorded  cat__funder  cat__installer  \\\n",
       "0                  1998.0               318.0        252.0           316.0   \n",
       "1                  2000.0               217.0        177.0           473.0   \n",
       "2                  2000.0               142.0        615.0           679.0   \n",
       "3                  2000.0               162.0        375.0           329.0   \n",
       "4                  1997.0                84.0        579.0           731.0   \n",
       "\n",
       "   cat__wpt_name  cat__basin  cat__subvillage  cat__region  cat__lga  \\\n",
       "0        24839.0         0.0            218.0          8.0       2.0   \n",
       "1        20890.0         0.0           7203.0          2.0       4.0   \n",
       "2        21231.0         2.0           1287.0         10.0      61.0   \n",
       "3        27339.0         6.0          15231.0         10.0      58.0   \n",
       "4        12815.0         8.0          12849.0         11.0      36.0   \n",
       "\n",
       "   cat__ward  cat__public_meeting  cat__recorded_by  cat__scheme_management  \\\n",
       "0       19.0                  1.0               0.0                     9.0   \n",
       "1      830.0                  1.0               0.0                     6.0   \n",
       "2     1519.0                  1.0               0.0                     6.0   \n",
       "3      173.0                  1.0               0.0                     6.0   \n",
       "4      143.0                  1.0               0.0                     6.0   \n",
       "\n",
       "   cat__scheme_name  cat__permit  cat__extraction_type  \\\n",
       "0             551.0          1.0                   3.0   \n",
       "1             551.0          1.0                   4.0   \n",
       "2             551.0          0.0                   9.0   \n",
       "3             551.0          1.0                   3.0   \n",
       "4             551.0          1.0                   9.0   \n",
       "\n",
       "   cat__extraction_type_group  cat__extraction_type_class  cat__management  \\\n",
       "0                         1.0                         0.0              9.0   \n",
       "1                         2.0                         1.0              7.0   \n",
       "2                         6.0                         3.0              7.0   \n",
       "3                         1.0                         0.0              7.0   \n",
       "4                         6.0                         3.0              7.0   \n",
       "\n",
       "   cat__management_group  cat__payment  cat__payment_type  cat__water_quality  \\\n",
       "0                    4.0           4.0                5.0                 6.0   \n",
       "1                    4.0           0.0                2.0                 6.0   \n",
       "2                    4.0           0.0                2.0                 6.0   \n",
       "3                    4.0           3.0                1.0                 6.0   \n",
       "4                    4.0           5.0                3.0                 4.0   \n",
       "\n",
       "   cat__quality_group  cat__quantity  cat__quantity_group  cat__source  \\\n",
       "0                 2.0            2.0                  2.0          8.0   \n",
       "1                 2.0            1.0                  1.0          7.0   \n",
       "2                 2.0            1.0                  1.0          7.0   \n",
       "3                 2.0            2.0                  2.0          6.0   \n",
       "4                 4.0            1.0                  1.0          7.0   \n",
       "\n",
       "   cat__source_type  cat__source_class  cat__waterpoint_type  \\\n",
       "0               6.0                0.0                   1.0   \n",
       "1               5.0                0.0                   4.0   \n",
       "2               5.0                0.0                   6.0   \n",
       "3               4.0                1.0                   1.0   \n",
       "4               5.0                0.0                   6.0   \n",
       "\n",
       "   cat__waterpoint_type_group  \n",
       "0                         1.0  \n",
       "1                         3.0  \n",
       "2                         5.0  \n",
       "3                         1.0  \n",
       "4                         5.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualización tras el preprocesado\n",
    "cols_rf = preprocessor_rf.get_feature_names_out()\n",
    "df_rf_viz = pd.DataFrame(X_rf_processed, columns=cols_rf)\n",
    "print(f\"Tamaño del dataset RF: {df_rf_viz.shape}\")\n",
    "display(df_rf_viz.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bca992",
   "metadata": {},
   "source": [
    "## Ajuste de hiperparámetros para bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce03ac81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando ajuste de Random Forest...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Mejor Accuracy RF (CV): 0.7797\n",
      "Mejores Parámetros RF: {'classifier__max_depth': 20, 'classifier__min_samples_split': 11, 'classifier__n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "# 1. Definimos la rejilla\n",
    "# Random Forest tiene muchos parámetros, nos centramos en los que controlan la complejidad\n",
    "param_grid_rf = {\n",
    "    # Número de árboles (más es mejor, pero más lento. 100 es estándar)\n",
    "    'classifier__n_estimators': [9, 10], \n",
    "    # Profundidad máxima: Evita que el árbol memorice el ruido\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    # Mínimo de muestras para dividir un nodo (regularización)\n",
    "    'classifier__min_samples_split': [6, 11]\n",
    "    # Nota: No ajustamos el selector aquí para ahorrar tiempo, \n",
    "    # asumimos que el SelectFromModel por defecto funciona bien.\n",
    "}\n",
    "\n",
    "# 2. Configuración del GridSearch\n",
    "grid_rf = GridSearchCV(\n",
    "    estimator=rf_pipeline_final,\n",
    "    param_grid=param_grid_rf,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 3. Ejecución\n",
    "print(\"Iniciando ajuste de Random Forest...\")\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "# 4. Resultados\n",
    "print(f\"Mejor Accuracy RF (CV): {grid_rf.best_score_:.4f}\")\n",
    "print(f\"Mejores Parámetros RF: {grid_rf.best_params_}\")\n",
    "\n",
    "# Guardamos el mejor modelo\n",
    "best_rf_model = grid_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403dd7aa",
   "metadata": {},
   "source": [
    "En el caso del ensemble de tipo Bagging (Random Forest), la estrategia de tuning se centró en el control del sobreajuste (overfitting). Mediante validación cruzada, ajustamos la profundidad máxima de los árboles (max_depth) y el número mínimo de muestras para realizar una división (min_samples_split). Buscamos un equilibrio entre la capacidad del modelo para capturar patrones complejos (árboles profundos) y la necesidad de generalización (árboles podados), aprovechando la robustez natural que ofrece el promediado de múltiples estimadores (n_estimators)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f506d76e",
   "metadata": {},
   "source": [
    "# Evaluación de los mejores modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82834a30",
   "metadata": {},
   "source": [
    "Para finalizar la fase de desarrollo, realizamos una evaluación comparativa profunda utilizando las predicciones generadas por validación cruzada (cross_val_predict). Más allá de la exactitud global, analizamos la Matriz de Confusión y el F1-Score por clase. Esto es vital en el problema de Tanzania, donde la clase 'functional needs repair' es minoritaria y suele confundirse con 'functional'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf0b96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluación detallada para Mejor kNN ---\n"
     ]
    }
   ],
   "source": [
    "# Función auxiliar para reportar resultados\n",
    "def evaluar_modelo(modelo, X, y, nombre):\n",
    "    print(f\"\\n--- Evaluación detallada para {nombre} ---\")\n",
    "    \n",
    "    y_pred_cv = cross_val_predict(modelo, X, y, cv=5, n_jobs=3)\n",
    "    \n",
    "    # Reporte numérico\n",
    "    print(classification_report(y, y_pred_cv, target_names=le.classes_))\n",
    "    \n",
    "    # Matriz de confusión visual\n",
    "    ConfusionMatrixDisplay.from_predictions(\n",
    "        y, y_pred_cv, \n",
    "        display_labels=le.classes_, \n",
    "        xticks_rotation='vertical',\n",
    "        cmap='Blues',\n",
    "        normalize='true' # Normalizamos para ver porcentajes de error por clase\n",
    "    )\n",
    "    plt.title(f\"Matriz de Confusión: {nombre}\")\n",
    "    plt.show()\n",
    "\n",
    "# Ejecutamos para ambos modelos ganadores\n",
    "evaluar_modelo(best_knn_model, X_train, y_train, \"Mejor kNN\")\n",
    "evaluar_modelo(best_rf_model, X_train, y_train, \"Mejor Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eb74a3",
   "metadata": {},
   "source": [
    "Como se observa en los gráficos, [AQUÍ DIRÁS TU CONCLUSIÓN: ej. Random Forest logra discriminar mejor la clase minoritaria gracias a su manejo de interacciones no lineales, mientras que kNN sufre más dispersión en las fronteras de decisión]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fa11e9",
   "metadata": {},
   "source": [
    "# Predicciones sobre test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b036cf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "y_test = pd.read_csv(\"y_test.csv\").values.ravel()\n",
    "\n",
    "# 2. APLICAR PREPROCESAMIENTO MANUAL AL TEST\n",
    "# ¡CRÍTICO! El pipeline hace casi todo, pero lo de los ceros lo hicimos a mano.\n",
    "# Si no hacemos esto en el test, el modelo fallará.\n",
    "cols_with_zeros_as_nan = ['construction_year', 'gps_height']\n",
    "for col in cols_with_zeros_as_nan:\n",
    "    X_test[col] = X_test[col].replace(0, np.nan)\n",
    "\n",
    "# Codificar la Y del test igual que hicimos con el train\n",
    "y_test = le.transform(y_test) # OJO: Usamos .transform(), NO .fit_transform()\n",
    "\n",
    "print(\"Test preparado. Dimensiones:\", X_test.shape)\n",
    "\n",
    "# 3. Predicciones Finales\n",
    "print(\"\\nGenerando predicciones finales...\")\n",
    "y_pred_test_knn = best_knn_model.predict(X_test)\n",
    "y_pred_test_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "# 4. Cálculo de Métricas Finales\n",
    "acc_knn = accuracy_score(y_test, y_pred_test_knn)\n",
    "f1_knn = f1_score(y_test, y_pred_test_knn, average='macro')\n",
    "\n",
    "acc_rf = accuracy_score(y_test, y_pred_test_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_test_rf, average='macro')\n",
    "\n",
    "print(f\"--- RESULTADOS FINALES EN TEST ---\")\n",
    "print(f\"KNN -> Accuracy: {acc_knn:.4f} | F1-Macro: {f1_knn:.4f}\")\n",
    "print(f\"RF  -> Accuracy: {acc_rf:.4f} | F1-Macro: {f1_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc04d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejor puntuación de validación (CV) de los grids\n",
    "val_score_knn = grid_knn.best_score_\n",
    "val_score_rf = grid_rf.best_score_\n",
    "\n",
    "# Datos para la gráfica\n",
    "labels = ['KNN', 'Random Forest']\n",
    "val_scores = [val_score_knn, val_score_rf]\n",
    "test_scores = [acc_knn, acc_rf]\n",
    "\n",
    "x = np.arange(len(labels))  # Posiciones de las etiquetas\n",
    "width = 0.35  # Ancho de las barras\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "rects1 = ax.bar(x - width/2, val_scores, width, label='Validación (Train CV)', color='skyblue')\n",
    "rects2 = ax.bar(x + width/2, test_scores, width, label='Test Final', color='orange')\n",
    "\n",
    "# Añadir textos\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Evolución del Rendimiento: Validación vs Test Final')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1) # Accuracy va de 0 a 1\n",
    "\n",
    "# Función para poner el numerito encima de la barra\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.3f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
